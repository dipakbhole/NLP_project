{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\dell\\anaconda3\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from gensim) (1.21.6)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from gensim) (6.4.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: Cython==0.29.28 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from gensim) (0.29.28)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import collections\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer  # For Lemmetization of words\n",
    "from nltk.corpus import stopwords  # Load list of stopwords\n",
    "from nltk import word_tokenize # Convert paragraph in tokens\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from gensim.models import word2vec # For represent words in vectors\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>broadband challenges tv viewing the number of ...</td>\n",
       "      <td>gardener wins double in glasgow britain s jaso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap boss arrested over drug find rap mogul mar...</td>\n",
       "      <td>amnesty chief laments war failure the lack of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player burn-out worries robinson england coach...</td>\n",
       "      <td>hanks greeted at wintry premiere hollywood sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hearts of oak 3-2 cotonsport hearts of oak set...</td>\n",
       "      <td>redford s vision of sundance despite sporting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir paul rocks super bowl crowds sir paul mcca...</td>\n",
       "      <td>mauresmo opens with victory in la amelie maure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>uk directors guild nominees named martin scors...</td>\n",
       "      <td>steel firm  to cut  45 000 jobs mittal steel  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>u2 to play at grammy awards show irish rock ba...</td>\n",
       "      <td>israel looks to us for bank chief israel has a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>pountney handed ban and fine northampton coach...</td>\n",
       "      <td>india and iran in gas export deal india has si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>belle named  best scottish band  belle &amp; sebas...</td>\n",
       "      <td>mido makes third apology ahmed  mido  hossam h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>criminal probe on citigroup deals traders at u...</td>\n",
       "      <td>former ni minister scott dies former northern ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text1  \\\n",
       "0     broadband challenges tv viewing the number of ...   \n",
       "1     rap boss arrested over drug find rap mogul mar...   \n",
       "2     player burn-out worries robinson england coach...   \n",
       "3     hearts of oak 3-2 cotonsport hearts of oak set...   \n",
       "4     sir paul rocks super bowl crowds sir paul mcca...   \n",
       "...                                                 ...   \n",
       "2995  uk directors guild nominees named martin scors...   \n",
       "2996  u2 to play at grammy awards show irish rock ba...   \n",
       "2997  pountney handed ban and fine northampton coach...   \n",
       "2998  belle named  best scottish band  belle & sebas...   \n",
       "2999  criminal probe on citigroup deals traders at u...   \n",
       "\n",
       "                                                  text2  \n",
       "0     gardener wins double in glasgow britain s jaso...  \n",
       "1     amnesty chief laments war failure the lack of ...  \n",
       "2     hanks greeted at wintry premiere hollywood sta...  \n",
       "3     redford s vision of sundance despite sporting ...  \n",
       "4     mauresmo opens with victory in la amelie maure...  \n",
       "...                                                 ...  \n",
       "2995  steel firm  to cut  45 000 jobs mittal steel  ...  \n",
       "2996  israel looks to us for bank chief israel has a...  \n",
       "2997  india and iran in gas export deal india has si...  \n",
       "2998  mido makes third apology ahmed  mido  hossam h...  \n",
       "2999  former ni minister scott dies former northern ...  \n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv(\"Precily_Text_Similarity.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text1    0\n",
       "text2    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() # Check if text data have any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:57<00:00,  7.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# Combining all the above stundents \n",
    "\n",
    "preprocessed_text1 = []\n",
    "\n",
    "# tqdm is for printing the status bar\n",
    "\n",
    "for sentance in tqdm(df['text1'].values):\n",
    "    sent = decontracted(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "\n",
    "    sent = ' '.join(e for e in sent.split() if e not in stopwords.words('english'))\n",
    "    preprocessed_text1.append(sent.lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>broadband challenges tv viewing number europea...</td>\n",
       "      <td>gardener wins double in glasgow britain s jaso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap boss arrested drug find rap mogul marion s...</td>\n",
       "      <td>amnesty chief laments war failure the lack of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player burn worries robinson england coach and...</td>\n",
       "      <td>hanks greeted at wintry premiere hollywood sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text1  \\\n",
       "0  broadband challenges tv viewing number europea...   \n",
       "1  rap boss arrested drug find rap mogul marion s...   \n",
       "2  player burn worries robinson england coach and...   \n",
       "\n",
       "                                               text2  \n",
       "0  gardener wins double in glasgow britain s jaso...  \n",
       "1  amnesty chief laments war failure the lack of ...  \n",
       "2  hanks greeted at wintry premiere hollywood sta...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging preprocessed_text1 in text_data\n",
    "\n",
    "df['text1'] = preprocessed_text1\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [06:59<00:00,  7.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# Combining all the above stundents \n",
    "from tqdm import tqdm\n",
    "preprocessed_text2 = []\n",
    "\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(df['text2'].values):\n",
    "    sent = decontracted(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "   \n",
    "    sent = ' '.join(e for e in sent.split() if e not in stopwords.words('english'))\n",
    "    preprocessed_text2.append(sent.lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>broadband challenges tv viewing number europea...</td>\n",
       "      <td>gardener wins double glasgow britain jason gar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap boss arrested drug find rap mogul marion s...</td>\n",
       "      <td>amnesty chief laments war failure lack public ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player burn worries robinson england coach and...</td>\n",
       "      <td>hanks greeted wintry premiere hollywood star t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text1  \\\n",
       "0  broadband challenges tv viewing number europea...   \n",
       "1  rap boss arrested drug find rap mogul marion s...   \n",
       "2  player burn worries robinson england coach and...   \n",
       "\n",
       "                                               text2  \n",
       "0  gardener wins double glasgow britain jason gar...  \n",
       "1  amnesty chief laments war failure lack public ...  \n",
       "2  hanks greeted wintry premiere hollywood star t...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging preprocessed_text2 in text_data\n",
    "\n",
    "df['text2'] = preprocessed_text2\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenizer(text):\n",
    "            #tokenizes and stems the text\n",
    "            tokens = word_tokenize(text)\n",
    "            lemmatizer = WordNetLemmatizer() \n",
    "            tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "            return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre_trained Google News Vectors after download file\n",
    "\n",
    "wordmodelfile=\"GoogleNews-vectors-negative300.bin.gz\"\n",
    "wordmodel= gensim.models.KeyedVectors.load_word2vec_format(wordmodelfile, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code check if word in text1 & text2 present in our google news vectors vocabalry.\n",
    "# if not it removes that word and if present it compares similarity score between text1 and text2 words\n",
    "\n",
    "\n",
    "similarity = [] # List for store similarity score\n",
    "\n",
    "\n",
    "\n",
    "for ind in df.index:\n",
    "    \n",
    "        s1 = df['text1'][ind]\n",
    "        s2 = df['text2'][ind]\n",
    "        \n",
    "        if s1==s2:\n",
    "                 similarity.append(0.0) # 0 means highly similar\n",
    "                \n",
    "        else:   \n",
    "\n",
    "            s1words = word_tokenizer(s1)\n",
    "            s2words = word_tokenizer(s2)\n",
    "            \n",
    "           \n",
    "            \n",
    "            vocab = wordmodel.index_to_key #the vocabulary considered in the word embeddings\n",
    "            \n",
    "            if len(s1words and s2words)==0:\n",
    "                    similarity.append(1.0)\n",
    "\n",
    "            else:\n",
    "                \n",
    "                for word in s1words.copy(): #remove sentence words not found in the vocab\n",
    "                    if (word not in vocab):\n",
    "                           \n",
    "                            \n",
    "                            s1words.remove(word)\n",
    "                        \n",
    "                    \n",
    "                for word in s2words.copy(): #idem\n",
    "\n",
    "                    if (word not in vocab):\n",
    "                           \n",
    "                            s2words.remove(word)\n",
    "                            \n",
    "                            \n",
    "                similarity.append((1-wordmodel.n_similarity(s1words, s2words))) # as it is given 1 means highly dissimilar & 0 means highly similar\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.314564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.366671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.282510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Similarity_score\n",
       "0          0.314564\n",
       "1          0.366671\n",
       "2          0.282510"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Unique_ID and similarity\n",
    "\n",
    "final_score = pd.DataFrame({\n",
    "                     'Similarity_score':similarity})\n",
    "final_score.head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE DF as CSV file \n",
    "\n",
    "final_score.to_csv('final_score.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
